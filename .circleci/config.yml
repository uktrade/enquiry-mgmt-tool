version: 2

aliases:
  - &data_hub_api
    image: quay.io/uktrade/data-hub-api:master
    environment:
      AWS_DEFAULT_REGION: eu-west-2
      AWS_ACCESS_KEY_ID: foo
      AWS_SECRET_ACCESS_KEY: bar
      DATABASE_URL: postgresql://postgres:datahub@postgres/datahub
      MI_DATABASE_URL: postgresql://postgres:datahub@mi-postgres/mi
      DEBUG: 'False'
      DEFAULT_BUCKET: baz
      DJANGO_SECRET_KEY: topSecret
      DJANGO_SETTINGS_MODULE: config.settings.local
      ENABLE_CELERY_ES_SYNC_OBJECT: 'True'
      ES_INDEX_PREFIX: test_index
      ES5_URL: http://localhost:9200
      POSTGRES_URL: tcp://postgres:5432
      MI_POSTGRES_URL: tcp://mi-postgres:5432
      REDIS_BASE_URL: redis://localhost:6379
      REDIS_CACHE_DB: 5
      REDIS_CELERY_DB: 6
      SSO_ENABLED: 'True'
      RESOURCE_SERVER_INTROSPECTION_URL: http://localhost:8080/o/introspect # required but not used as user with token has been created in backend setup script
      RESOURCE_SERVER_AUTH_TOKEN: sso-token
      STAFF_SSO_BASE_URL: http://localhost:8080/
      STAFF_SSO_AUTH_TOKEN: sso-token
      WEB_CONCURRENCY: 2
      ACTIVITY_STREAM_ACCESS_KEY_ID: some-id
      ACTIVITY_STREAM_SECRET_ACCESS_KEY: some-secret
      DISABLE_PAAS_IP_CHECK: 'True'
      DATA_HUB_FRONTEND_ACCESS_KEY_ID: frontend-key-id
      DATA_HUB_FRONTEND_SECRET_ACCESS_KEY: frontend-key
      ADMIN_OAUTH2_ENABLED: 'False'
      # Workaround for Docker/CircleCI compatibility problem with Python 3.8
      COLUMNS: 80
    command: ./setup-uat.sh
  - &data_hub_api_celery
    <<: *data_hub_api
    # Note: By default Celery will default to the number of CPU cores, which can be a large number on CircleCI like 36
    # which then ends up causing out-of-memory errors
    command: celery worker -A config -l info -Q celery,long-running --concurrency 3

jobs:
  build:
    parameters:
      python_image:
        type: string

      postgres_image:
        type: string

    environment:
      DEBUG: 'True'
      DJANGO_SECRET_KEY: 'supersecretkey'
      POSTGRES_DB_PASSWORD: 'password'
      POSTGRES_DB_HOST: 'localhost'
      DATA_HUB_ACCESS_TOKEN: 'datahub-access-token'
      DATA_HUB_METADATA_URL: 'https://datahub/metadata'
      DATA_HUB_COMPANY_SEARCH_URL: 'https://datahub/company/search'
      DATA_HUB_CONTACT_SEARCH_URL: 'https://datahub/contact/search'
      DATA_HUB_HAWK_ID: 'hawk-id'
      DATA_HUB_HAWK_KEY: 'hawk-key'
      DATA_HUB_METADATA_FETCH_INTERVAL: '4'
      DATABASE_URL: postgresql://postgres:password@localhost:5432/postgres
      FEATURE_ENFORCE_STAFF_SSO_ENABLED: 1
      AUTHBROKER_URL: https://sso.trade.gov.uk
      AUTHBROKER_CLIENT_ID: somestring
      AUTHBROKER_CLIENT_SECRET: somestring
      AUTHBROKER_TOKEN_SESSION_KEY: _authbroker_token
      AUTHBROKER_STAFF_SSO_SCOPE: required-scope-values

    docker:
      - image: quay.io/uktrade/enquiry-mgmt-tool
      - image: circleci/postgres:9.6
        environment:
          POSTGRES_USER: postgres
          POSTGRES_DB: postgres
          POSTGRES_PASSWORD: password
          DATABASE_URL: postgresql://postgres:password@localhost:5432/postgres
      - image: redis:3.2.10
      - image: postgres:10
        name: postgres
        environment:
          POSTGRES_DB: datahub
          POSTGRES_PASSWORD: datahub
      - image: postgres:9.6
        name: mi-postgres
        environment:
          POSTGRES_DB: mi
          POSTGRES_PASSWORD: datahub
      - image: docker.elastic.co/elasticsearch/elasticsearch:6.8.2
      - <<: *data_hub_api
      - <<: *data_hub_api_celery

    steps:
      - checkout
      - run:
          name: Wait for db to become available
          command: dockerize -wait tcp://localhost:5432 -timeout 1m

      - restore_cache:
          keys:
            - v1-dependencies-{{ checksum "requirements.txt" }}
          paths:
            - ./venv

      - run:
          name: Install dependencies
          command: |
            python3 -m venv venv
            . venv/bin/activate
            pip install -r requirements.txt

      - save_cache:
          name: Save pip cache
          key: v1-dependencies-{{ checksum "requirements.txt" }}
          paths:
            - ./venv

      - run:
          name: Run tests
          command: |
            . venv/bin/activate
            python -m pytest -s -vvv app/enquiries/tests

      - run:
          name: Wait for Data Hub API to become available
          command: dockerize -wait tcp://localhost:8000 -timeout 5m

      - run:
          name: Run e2e tests
          command: cypress run --browser chrome
